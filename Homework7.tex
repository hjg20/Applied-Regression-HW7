% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage{soul}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={STA 5207: Homework 7},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{STA 5207: Homework 7}
\author{}
\date{\vspace{-2.5em}Due: March, 8th by 11:59 PM}

\begin{document}
\maketitle

Include your R code in an R chunks as part of your answer. In addition,
your written answer to each exercise should be self-contained so that
the grader can determine your solution without reading your code or
deciphering its output.

\hypertarget{exercise-1-longley-macroeconomic-data-50-points}{%
\subsection{\texorpdfstring{Exercise 1 (\texttt{longley} Macroeconomic
Data) {[}50
points{]}}{Exercise 1 (longley Macroeconomic Data) {[}50 points{]}}}\label{exercise-1-longley-macroeconomic-data-50-points}}

For this exercise we will use the built-in \texttt{longley} data set.
You can also find the data in \texttt{longley.csv} on Canvas. The data
set contains macroeconomic data for predicting unemployment. The
variables in the model are

\begin{itemize}
\tightlist
\item
  \texttt{GNP.deflator}: GNP implicit price deflator (1954 = 100)
\item
  \texttt{GNP}: Gross national product.
\item
  \texttt{Unemployed}: Number of unemployed.
\item
  \texttt{Armed.Forces}: Number of people in the armed forces.
\item
  \texttt{Population}: `noninstituionalized population \(\geq 14\) years
  of age.
\item
  \texttt{Year}: The year.
\item
  \texttt{Employed}: Number of people employed.
\end{itemize}

In the following exercise, we will model the \texttt{Employed} variable.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (6 points) How many pairs of predictors are highly correlated?
  Consider ``highly'' correlated to be a sample correlation above 0.7.
  What is the largest correlation between any pair of predictors in the
  data set?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ longley}
\NormalTok{preds }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(data, }\SpecialCharTok{{-}}\NormalTok{Employed)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{cor}\NormalTok{(preds), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              GNP.deflator   GNP Unemployed Armed.Forces Population  Year
## GNP.deflator        1.000 0.992      0.621        0.465      0.979 0.991
## GNP                 0.992 1.000      0.604        0.446      0.991 0.995
## Unemployed          0.621 0.604      1.000       -0.177      0.687 0.668
## Armed.Forces        0.465 0.446     -0.177        1.000      0.364 0.417
## Population          0.979 0.991      0.687        0.364      1.000 0.994
## Year                0.991 0.995      0.668        0.417      0.994 1.000
\end{verbatim}

  \textbf{Answer:} Highly correlated pairs of predictors (predictors
  with a sample correlation above 0.7) are \ul{GNP and GNP.deflator},
  \ul{Population and GNP.deflator}, \ul{Year and GNP.deflator},
  \ul{Population and GNP}, \ul{Year and GNP}, and \ul{Year and
  Population}. The largest correlation between any pair of predictors in
  the dataset is the correlation between Year and GNP with a correlation
  of .995.
\item
  (6 points) Fit a model with \texttt{Employed} as the response and the
  remaining variables as predictors. Give the condition number. Does
  multicollinearity appear to be a problem

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(olsrr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'olsrr'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:datasets':
## 
##     rivers
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Employed }\SpecialCharTok{\textasciitilde{}}\NormalTok{., }\AttributeTok{data=}\NormalTok{data)}
\FunctionTok{summary}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Employed ~ ., data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.41011 -0.15767 -0.02816  0.10155  0.45539 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -3.482e+03  8.904e+02  -3.911 0.003560 ** 
## GNP.deflator  1.506e-02  8.492e-02   0.177 0.863141    
## GNP          -3.582e-02  3.349e-02  -1.070 0.312681    
## Unemployed   -2.020e-02  4.884e-03  -4.136 0.002535 ** 
## Armed.Forces -1.033e-02  2.143e-03  -4.822 0.000944 ***
## Population   -5.110e-02  2.261e-01  -0.226 0.826212    
## Year          1.829e+00  4.555e-01   4.016 0.003037 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3049 on 9 degrees of freedom
## Multiple R-squared:  0.9955, Adjusted R-squared:  0.9925 
## F-statistic: 330.3 on 6 and 9 DF,  p-value: 4.984e-10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{ols\_eigen\_cindex}\NormalTok{(model)[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{], }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Eigenvalue Condition Index
## 1     6.8614          1.0000
## 2     0.0821          9.1417
## 3     0.0457         12.2557
## 4     0.0107         25.3366
## 5     0.0001        230.4239
## 6     0.0000       1048.0803
## 7     0.0000      43275.0435
\end{verbatim}

  \textbf{Answer:} The condition number is 43275.04. This is much
  greater than 30, so we say that multicollinearity appears to be a
  problem.
\item
  (6 points) Calculate and report the variance inflation factor (VIF)
  for each of the predictors. Which variable has the largest VIF? Do any
  of the VIFs suggest multicollinearity?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(faraway)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'faraway'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:olsrr':
## 
##     hsb
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## GNP.deflator          GNP   Unemployed Armed.Forces   Population         Year 
##    135.53244   1788.51348     33.61889      3.58893    399.15102    758.98060
\end{verbatim}

  \textbf{Answer:} The VIFs for each predictor are as follows:
  GNP.deflator = 135.5, GNP = 1788.5, Unemployed = 33.6, Armed.Forces =
  3.6, Population = 399.2, Year = 759. The variable with the largest VIF
  is GNP with a VIF of 1788.5. A VIF greater than 5 suggests
  colinearity, so all predictor's except for Armed.Force's VIF values
  suggest multicollinearity.
\item
  (6 points) What proportion of the observed variation in
  \texttt{Population} is explained by the linear relationship with the
  other predictors? Are there any variables that are nearly orthogonal
  to the others? Consider a low \(R^2_k\) to be less than 0.3.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(Population}\SpecialCharTok{\textasciitilde{}}\NormalTok{GNP.deflator}\SpecialCharTok{+}\NormalTok{GNP}\SpecialCharTok{+}\NormalTok{Unemployed}\SpecialCharTok{+}\NormalTok{Armed.Forces}\SpecialCharTok{+}\NormalTok{Year, }\AttributeTok{data=}\NormalTok{data))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Population ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
##     Year, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.57524 -0.18536  0.07539  0.24615  0.58666 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   1.618e+03  1.136e+03   1.424 0.184790    
## GNP.deflator -2.476e-01  8.932e-02  -2.772 0.019720 *  
## GNP           1.234e-01  2.591e-02   4.765 0.000763 ***
## Unemployed    1.638e-02  4.454e-03   3.678 0.004261 ** 
## Armed.Forces  1.791e-03  2.943e-03   0.608 0.556517    
## Year         -7.820e-01  5.872e-01  -1.332 0.212452    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4264 on 10 degrees of freedom
## Multiple R-squared:  0.9975, Adjusted R-squared:  0.9962 
## F-statistic: 796.3 on 5 and 10 DF,  p-value: 1.154e-12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1{-}1}\SpecialCharTok{/}\FunctionTok{vif}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## GNP.deflator          GNP   Unemployed Armed.Forces   Population         Year 
##    0.9926217    0.9994409    0.9702548    0.7213654    0.9974947    0.9986824
\end{verbatim}

  \textbf{Answer:} The proportion of the observed variation in
  Population that is explained by the linear relationship with the other
  predictors is 99.75\%. There are no variables that are nearly
  orthogonal to the others.
\item
  (6 points) Give the condition indices. How many near
  linear-dependencies are likely causing most of the problem?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(olsrr)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{ols\_eigen\_cindex}\NormalTok{(model), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Eigenvalue Condition Index intercept GNP.deflator   GNP Unemployed
## 1      6.861           1.000         0        0.000 0.000      0.000
## 2      0.082           9.142         0        0.000 0.000      0.014
## 3      0.046          12.256         0        0.000 0.000      0.001
## 4      0.011          25.337         0        0.000 0.001      0.065
## 5      0.000         230.424         0        0.457 0.016      0.006
## 6      0.000        1048.080         0        0.505 0.328      0.225
## 7      0.000       43275.043         1        0.038 0.655      0.689
##   Armed.Forces Population Year
## 1        0.000      0.000    0
## 2        0.092      0.000    0
## 3        0.064      0.000    0
## 4        0.427      0.000    0
## 5        0.115      0.010    0
## 6        0.000      0.831    0
## 7        0.302      0.160    1
\end{verbatim}

  \textbf{Answer:} There are 3 indexes in which the condition index is
  greater than 30. Therefore we can conclude that there are three
  linear-dependencies that are likely causing most of the problem.
\item
  (10 points) Fit a new model with \texttt{Employed} as the the response
  and the predictors from the model in part 2 that were significant (use
  \(\alpha = 0.05\)). Calculate and report the variance inflation factor
  for each of the predictors. Do any of the VIFs suggest
  multicollinearity?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Employed }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Unemployed }\SpecialCharTok{+}\NormalTok{ Armed.Forces }\SpecialCharTok{+}\NormalTok{ Year, }\AttributeTok{data=}\NormalTok{data)}
\FunctionTok{vif}\NormalTok{(new\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Unemployed Armed.Forces         Year 
##     3.317929     2.223317     3.890861
\end{verbatim}

  \textbf{Answer:} We choose Unemplyed, Armed.Forces, and Year as our
  predictors because they all had a p-value of less than 0.05 in the
  linear model from part 2. All VIFs are less than 5, so we conclude
  that collinearity is not a problem for this model.
\item
  (10 points) Use an \(F\)-test to compare the models in parts 2 and 6.
  Report the following:

  \begin{itemize}
  \tightlist
  \item
    The null hypothesis.
  \item
    The test statistic.
  \item
    The \(p\)-value of the test.
  \item
    A statistical decision at \(\alpha = 0.05\).
  \item
    Which model do you prefer, the model from part 2 or 6.
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(new\_model, model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: Employed ~ Unemployed + Armed.Forces + Year
## Model 2: Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + Population + 
##     Year
##   Res.Df     RSS Df Sum of Sq      F Pr(>F)
## 1     12 1.32336                           
## 2      9 0.83642  3   0.48694 1.7465  0.227
\end{verbatim}

  \textbf{Answer:} The null hypothesis is that the full model does not
  provide a significantly better fit to the data than the restricted
  model. The test-statistic for this test is 1.7465, and the p-value is
  0.227. Since the p-value is not less than our significance level of
  0.05, we do not reject the null hypothesis and thus conclude that the
  full model does not provide a significantly better fit to the data
  than the restricted model. Therefore, we would prefer the model from
  part 6 over the model from part 2.
\end{enumerate}

\hypertarget{exercise-2-the-sat-data-set-revisited-50-points}{%
\subsection{\texorpdfstring{Exercise 2 (The \texttt{sat} Data Set
Revisited) {[}50
points{]}}{Exercise 2 (The sat Data Set Revisited) {[}50 points{]}}}\label{exercise-2-the-sat-data-set-revisited-50-points}}

For this exercise we will use the \texttt{sat} data set from the
\texttt{faraway} package, which you analyzed in Homework \#3. In the
following exercise, we will model the \texttt{total} variable as a
function of \texttt{expend}, \texttt{salary}, and \texttt{ratio}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (8 points) Among the three predictors \texttt{expend},
  \texttt{salary}, and `ratio``, how many pairs of predictors are are
  highly correlated? Consider ``highly'' correlated to be a sample
  correlation above 0.7.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(faraway)}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(sat, total, expend, salary, ratio)}
\NormalTok{preds }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(data, }\SpecialCharTok{{-}}\NormalTok{total)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{cor}\NormalTok{(preds), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        expend salary  ratio
## expend  1.000  0.870 -0.371
## salary  0.870  1.000 -0.001
## ratio  -0.371 -0.001  1.000
\end{verbatim}

  \textbf{Answer:} Using 0.7 as highly correlated, we see that the only
  pair of predictors which are highly correlated are salary and expend
  with a correlation score of 0.870.
\item
  (8 points) Fit a model with \texttt{total} as the response and
  \texttt{expend}, \texttt{salary}, and \texttt{ratio} as the
  predictors. Give the condition number. Does multicollinearity appear
  to be a problem?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(total }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data=}\NormalTok{data)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{ols\_eigen\_cindex}\NormalTok{(model)[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{],}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Eigenvalue Condition Index
## 1     3.9393          1.0000
## 2     0.0516          8.7394
## 3     0.0074         23.1080
## 4     0.0017         48.1229
\end{verbatim}

  \textbf{Answer:} The condition number is 48.1229. Since the condition
  number is greater than 30, we should be concerned about collinearity.
\item
  (8 points) Calculate and report the variance inflation factor (VIF)
  for each of the predictors. Which variable has the largest VIF? Do any
  of the VIFs suggest multicollinearity?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   expend   salary    ratio 
## 9.387552 8.095274 2.285359
\end{verbatim}

  \textbf{Answer:} The VIF values are as follows: expend = 9.39, salary
  = 8.10, ratio = 2.29. The variable with the largest VIF is expend.
  Expend and Salary both have VIF values greater than 5 which suggests
  collinearity.
\item
  (10 points) Fit a new model with \texttt{total} as the response and
  \texttt{ratio} and the sum of \texttt{expend} and \texttt{salary} --
  that is \texttt{I(expend\ +\ salary)} -- as the predictors. Note that
  \texttt{expend} and \texttt{salary} have the same units (thousands of
  dollars), so adding them makes sense. Calculate and report the
  variance inflation factor for each of the two predictors. Do any of
  the VIFs suggest multicollinearity?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(total }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ratio }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(expend }\SpecialCharTok{+}\NormalTok{ salary), }\AttributeTok{data=}\NormalTok{data)}
\FunctionTok{vif}\NormalTok{(new\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              ratio I(expend + salary) 
##           1.005151           1.005151
\end{verbatim}

  \textbf{Answer:} After adding expend and salary together, both of the
  sum of these predictors and ratio have a VIF value of 1.005151. Since
  this value is less than 5 we can say that non of the VIFs suggest
  multicollinearity.
\item
  (6 points) Conduct a \(t\)-test at the 5\% significance level for each
  slope parameter for the model in part 4. Give the test statistic,
  \(p\)-value, and statistical decision for each test.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(new\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = total ~ ratio + I(expend + salary), data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -146.82  -43.88    5.57   39.93  126.55 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        1122.749     95.620  11.742  1.4e-15 ***
## ratio                 1.657      4.335   0.382  0.70399    
## I(expend + salary)   -4.536      1.372  -3.305  0.00182 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 68.59 on 47 degrees of freedom
## Multiple R-squared:  0.194,  Adjusted R-squared:  0.1597 
## F-statistic: 5.655 on 2 and 47 DF,  p-value: 0.006302
\end{verbatim}

  \textbf{Answer:} For the slope parameter corresponding to ratio, the
  test statistic is 0.382, the p-value is 0.704, and a statistical
  decision at the 5\% significance level is to not reject the null
  hypothesis and say that there is no significant linear relationship
  between ratio and total with the other predictor present in the model.
  For the slope parameter corresponding to the sum of expend and salary,
  the test statistic is -3.305, the p-value is 0.00182, and a
  statistical decision at the 5\% significance level is to reject the
  null hypothesis and say that there is a significant linear
  relationship between the sum of expend and salary and the response,
  total, with the other predictor present in the model.
\item
  (10 points) Use an \(F\)-test to compare the models in parts 2 and 4.
  Report the following:

  \begin{itemize}
  \tightlist
  \item
    The null hypothesis (\textbf{Hint}: We are testing a linear
    constraint, see the slides on MLR, page 39).
  \item
    The test statistic.
  \item
    The \(p\)-value of the test.
  \item
    A statistical decision at \(\alpha = 0.05\).
  \item
    Which model do you prefer, the model from part 2 or part 4.
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(new\_model, model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: total ~ ratio + I(expend + salary)
## Model 2: total ~ expend + salary + ratio
##   Res.Df    RSS Df Sum of Sq     F Pr(>F)
## 1     47 221106                          
## 2     46 216812  1    4293.7 0.911 0.3448
\end{verbatim}

  \textbf{Answer:} The null hypothesis of this F-test is that there is
  no sufficient improvement in the linear model to predict ``total''
  when the predictors expend and salary are combined into one predictor.
  The test statistic is 0.911 and the p-value is 0.3448. A statistical
  decision at \(\alpha=0.05\) is to reject the null hypothesis at a
  p-value of less than 0.05. Since our p-value is greater than 0.05, we
  do not reject the null and thus conclude that there is no sufficient
  improvement in the linear model to predict ``total'' when the
  predictors expend and salary are combined into one predictor.
  Therefore, we would prefer the model from part 2.
\end{enumerate}

\end{document}
